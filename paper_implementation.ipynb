{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paper_implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TKratter/Advanced-Time-Series/blob/main/paper_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8CD2TEci6Ft",
        "outputId": "8032e81c-6918-4932-b144-2778857737a3"
      },
      "source": [
        "%pylab inline\n",
        "plt.style.use(\"bmh\")\n",
        "plt.rcParams[\"figure.figsize\"] = (6,6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zezhKykqVf6"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sL_rm2nmPec"
      },
      "source": [
        "import pathlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "DATA_DIR = pathlib.Path(\"data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMnGvJHgmZ9X"
      },
      "source": [
        "# PyTorch imports\r\n",
        "import torch\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch import nn\r\n",
        "from torch.utils.data import DataLoader, Dataset\r\n",
        "\r\n",
        "# PyTorch Lightning imports\r\n",
        "import pytorch_lightning as pl"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnrCBisXqcvW"
      },
      "source": [
        "Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PzJGQTKm9AX"
      },
      "source": [
        "class ElectricityLoadDataset(Dataset):\r\n",
        "    \"\"\"Sample data from electricity load dataset (per household, resampled to one hour).\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, df, samples, hist_len=168, fct_len=24):\r\n",
        "        self.hist_num = hist_len\r\n",
        "        self.fct_num = fct_len\r\n",
        "        self.hist_len = pd.Timedelta(hours=hist_len)\r\n",
        "        self.fct_len = pd.Timedelta(hours=fct_len)\r\n",
        "        self.offset = pd.Timedelta(hours=1)\r\n",
        "        self.samples = samples\r\n",
        "\r\n",
        "        self.max_ts = df.index.max() - self.hist_len - self.fct_len + self.offset\r\n",
        "        self.raw_data = df.copy()\r\n",
        "\r\n",
        "        assert samples <= self.raw_data[:self.max_ts].shape[0]\r\n",
        "\r\n",
        "        self.sample()\r\n",
        "\r\n",
        "    def sample(self):\r\n",
        "        \"\"\"Sample individual series as needed.\"\"\"\r\n",
        "\r\n",
        "        # Calculate actual start for each household\r\n",
        "        self.clean_start_ts = (self.raw_data!=0).idxmax()\r\n",
        "\r\n",
        "        households = []\r\n",
        "\r\n",
        "        for hh in self.raw_data.columns:\r\n",
        "            hh_start = self.clean_start_ts[hh]\r\n",
        "            hh_nsamples = min(self.samples, self.raw_data.loc[hh_start:self.max_ts].shape[0])\r\n",
        "\r\n",
        "            hh_samples = (self.raw_data\r\n",
        "                          .loc[hh_start:self.max_ts]\r\n",
        "                          .index\r\n",
        "                          .to_series()\r\n",
        "                          .sample(hh_nsamples, replace=False)\r\n",
        "                          .index)\r\n",
        "            households.extend([(hh, start_ts) for start_ts in hh_samples])\r\n",
        "\r\n",
        "        self.samples = pd.DataFrame(households, columns=(\"household\", \"start_ts\"))\r\n",
        "\r\n",
        "        # Adding calendar features\r\n",
        "        self.raw_data[\"yearly_cycle\"] = np.sin(2 * np.pi * self.raw_data.index.dayofyear / 366)\r\n",
        "        self.raw_data[\"weekly_cycle\"] = np.sin(2 * np.pi * self.raw_data.index.dayofweek / 7)\r\n",
        "        self.raw_data[\"daily_cycle\"] = np.sin(2 * np.pi * self.raw_data.index.hour / 24)\r\n",
        "        self.calendar_features = [\"yearly_cycle\", \"weekly_cycle\", \"daily_cycle\"]\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return self.samples.shape[0]\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        household, start_ts = self.samples.iloc[idx]\r\n",
        "\r\n",
        "        hs, he = start_ts, start_ts + self.hist_len - self.offset\r\n",
        "        fs, fe = he + self.offset, he + self.fct_len\r\n",
        "\r\n",
        "        hist_data = self.raw_data.loc[hs:, [household] + self.calendar_features].iloc[:self.hist_num]\r\n",
        "        fct_data = self.raw_data.loc[fs:, [household] + self.calendar_features].iloc[:self.fct_num]\r\n",
        "\r\n",
        "        return (torch.Tensor(hist_data.values),\r\n",
        "                torch.Tensor(fct_data.values))"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}